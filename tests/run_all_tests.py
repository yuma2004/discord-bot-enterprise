#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼
å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã‚’åŠ¹ç‡çš„ã«å®Ÿè¡Œã—ã€è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
"""

import unittest
import sys
import os
import time
from io import StringIO
import json
from datetime import datetime

# ãƒ†ã‚¹ãƒˆç”¨ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
os.environ.setdefault('DISCORD_TOKEN', 'test_token')
os.environ.setdefault('DISCORD_GUILD_ID', '123456789')
os.environ.setdefault('DATABASE_URL', 'test_runner.db')
os.environ.setdefault('ENVIRONMENT', 'test')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


class ColoredTestResult(unittest.TextTestResult):
    """ã‚«ãƒ©ãƒ¼å‡ºåŠ›ä»˜ããƒ†ã‚¹ãƒˆçµæœã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, stream, descriptions, verbosity):
        super().__init__(stream, descriptions, verbosity)
        self.test_results = []
        self.start_time = None
        self.colors = {
            'green': '\033[92m',
            'red': '\033[91m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'purple': '\033[95m',
            'cyan': '\033[96m',
            'white': '\033[97m',
            'reset': '\033[0m'
        }
    
    def startTest(self, test):
        super().startTest(test)
        self.start_time = time.time()
        # ç°¡å˜ãªå‡ºåŠ›ï¼ˆverbosityã¯parentã‹ã‚‰å–å¾—ï¼‰
        if hasattr(self, 'verbosity') and self.verbosity > 1:
            self.stream.write(f"{self.colors['blue']}å®Ÿè¡Œä¸­: {test._testMethodName}{self.colors['reset']} ... ")
            self.stream.flush()
    
    def addSuccess(self, test):
        super().addSuccess(test)
        duration = time.time() - self.start_time
        self.test_results.append({
            'test': str(test),
            'status': 'SUCCESS',
            'duration': duration,
            'message': None
        })
        # æˆåŠŸæ™‚ã¯ç°¡æ½”ãªå‡ºåŠ›ã®ã¿
        pass
    
    def addError(self, test, err):
        super().addError(test, err)
        duration = time.time() - self.start_time
        self.test_results.append({
            'test': str(test),
            'status': 'ERROR',
            'duration': duration,
            'message': self._exc_info_to_string(err, test)
        })
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯åˆ¥é€”è¡¨ç¤º
        pass
    
    def addFailure(self, test, err):
        super().addFailure(test, err)
        duration = time.time() - self.start_time
        self.test_results.append({
            'test': str(test),
            'status': 'FAILURE',
            'duration': duration,
            'message': self._exc_info_to_string(err, test)
        })
        # å¤±æ•—æ™‚ã¯åˆ¥é€”è¡¨ç¤º
        pass
    
    def addSkip(self, test, reason):
        super().addSkip(test, reason)
        duration = time.time() - self.start_time
        self.test_results.append({
            'test': str(test),
            'status': 'SKIP',
            'duration': duration,
            'message': reason
        })
        # ã‚¹ã‚­ãƒƒãƒ—æ™‚ã¯åˆ¥é€”è¡¨ç¤º
        pass


class TestSuiteRunner:
    """ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.test_modules = [
            'test_basic',
            'test_attendance', 
            'test_database_integration',
            'test_error_handling',
            'test_performance'
        ]
        self.results = {}
        self.total_start_time = None
    
    def run_module_tests(self, module_name, verbosity=2):
        """ç‰¹å®šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª {module_name.upper()} ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        print(f"{'='*60}")
        
        try:
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            module = __import__(f'tests.{module_name}', fromlist=[''])
            
            # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä½œæˆ
            loader = unittest.TestLoader()
            suite = loader.loadTestsFromModule(module)
            
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ã§å®Ÿè¡Œ
            stream = StringIO()
            runner = unittest.TextTestRunner(
                stream=stream,
                verbosity=verbosity,
                resultclass=ColoredTestResult
            )
            
            start_time = time.time()
            result = runner.run(suite)
            end_time = time.time()
            
            # çµæœã‚’è¨˜éŒ²
            self.results[module_name] = {
                'tests_run': result.testsRun,
                'failures': len(result.failures),
                'errors': len(result.errors),
                'skipped': len(result.skipped),
                'success_count': result.testsRun - len(result.failures) - len(result.errors) - len(result.skipped),
                'duration': end_time - start_time,
                'details': getattr(result, 'test_results', []),
                'output': stream.getvalue()
            }
            
            # çµæœè¡¨ç¤º
            self._print_module_summary(module_name, self.results[module_name])
            
            return result.wasSuccessful()
            
        except ImportError as e:
            print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« {module_name} ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
            self.results[module_name] = {
                'tests_run': 0,
                'failures': 0,
                'errors': 1,
                'skipped': 0,
                'success_count': 0,
                'duration': 0,
                'details': [],
                'output': f"Import Error: {e}"
            }
            return False
        except Exception as e:
            print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« {module_name} ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            self.results[module_name] = {
                'tests_run': 0,
                'failures': 0,
                'errors': 1,
                'skipped': 0,
                'success_count': 0,
                'duration': 0,
                'details': [],
                'output': f"Error: {e}"
            }
            return False
    
    def _print_module_summary(self, module_name, result):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        total_tests = result['tests_run']
        success_count = result['success_count']
        failure_count = result['failures']
        error_count = result['errors']
        skip_count = result['skipped']
        duration = result['duration']
        
        print(f"\nğŸ“Š {module_name} ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   âœ… æˆåŠŸ: {success_count}/{total_tests}")
        if failure_count > 0:
            print(f"   âŒ å¤±æ•—: {failure_count}")
        if error_count > 0:
            print(f"   ğŸ”¥ ã‚¨ãƒ©ãƒ¼: {error_count}")
        if skip_count > 0:
            print(f"   âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: {skip_count}")
        print(f"   â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’")
        
        if total_tests > 0:
            success_rate = (success_count / total_tests) * 100
            if success_rate == 100:
                print(f"   ğŸ‰ æˆåŠŸç‡: {success_rate:.1f}% (å®Œç’§!)")
            elif success_rate >= 90:
                print(f"   ğŸ˜Š æˆåŠŸç‡: {success_rate:.1f}% (å„ªç§€)")
            elif success_rate >= 80:
                print(f"   ğŸ˜ æˆåŠŸç‡: {success_rate:.1f}% (æ™®é€š)")
            else:
                print(f"   ğŸ˜ æˆåŠŸç‡: {success_rate:.1f}% (è¦æ”¹å–„)")
    
    def run_all_tests(self, verbosity=2, save_report=True):
        """å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("ğŸš€ åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œé–‹å§‹")
        print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        self.total_start_time = time.time()
        
        successful_modules = 0
        total_modules = len(self.test_modules)
        
        # å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        for module_name in self.test_modules:
            success = self.run_module_tests(module_name, verbosity)
            if success:
                successful_modules += 1
        
        total_end_time = time.time()
        total_duration = total_end_time - self.total_start_time
        
        # å…¨ä½“çµæœã®è¡¨ç¤º
        self._print_overall_summary(successful_modules, total_modules, total_duration)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        if save_report:
            self._save_report()
        
        return successful_modules == total_modules
    
    def _print_overall_summary(self, successful_modules, total_modules, total_duration):
        """å…¨ä½“çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print(f"\n{'='*80}")
        print(f"ğŸ åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†")
        print(f"{'='*80}")
        
        # çµ±è¨ˆè¨ˆç®—
        total_tests = sum(r['tests_run'] for r in self.results.values())
        total_success = sum(r['success_count'] for r in self.results.values())
        total_failures = sum(r['failures'] for r in self.results.values())
        total_errors = sum(r['errors'] for r in self.results.values())
        total_skipped = sum(r['skipped'] for r in self.results.values())
        
        print(f"ğŸ“ˆ å…¨ä½“çµ±è¨ˆ:")
        print(f"   ğŸ¯ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æˆåŠŸç‡: {successful_modules}/{total_modules} ({successful_modules/total_modules*100:.1f}%)")
        print(f"   ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"   âœ… æˆåŠŸ: {total_success}")
        print(f"   âŒ å¤±æ•—: {total_failures}")
        print(f"   ğŸ”¥ ã‚¨ãƒ©ãƒ¼: {total_errors}")
        print(f"   âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: {total_skipped}")
        print(f"   â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_duration:.2f}ç§’")
        
        if total_tests > 0:
            overall_success_rate = (total_success / total_tests) * 100
            print(f"   ğŸ¯ å…¨ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%")
            
            if overall_success_rate == 100:
                print(f"   ğŸ‰ çµæœ: å®Œç’§! å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ!")
            elif overall_success_rate >= 95:
                print(f"   ğŸ˜Š çµæœ: å„ªç§€! ã»ã¼å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ!")
            elif overall_success_rate >= 80:
                print(f"   ğŸ˜ çµæœ: æ™®é€šã§ã™ã€‚ã„ãã¤ã‹ã®å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
            else:
                print(f"   ğŸ˜ çµæœ: è¦æ”¹å–„ã€‚å¤šãã®å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
        avg_test_duration = total_duration / total_tests if total_tests > 0 else 0
        tests_per_second = total_tests / total_duration if total_duration > 0 else 0
        
        print(f"\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™:")
        print(f"   å¹³å‡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“: {avg_test_duration:.4f}ç§’")
        print(f"   ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé€Ÿåº¦: {tests_per_second:.1f}ãƒ†ã‚¹ãƒˆ/ç§’")
        
        # å•é¡ŒãŒã‚ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        problematic_modules = []
        for module_name, result in self.results.items():
            if result['failures'] > 0 or result['errors'] > 0:
                problematic_modules.append(module_name)
        
        if problematic_modules:
            print(f"\nâš ï¸  å•é¡ŒãŒã‚ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«:")
            for module in problematic_modules:
                result = self.results[module]
                print(f"   - {module}: {result['failures']}å¤±æ•—, {result['errors']}ã‚¨ãƒ©ãƒ¼")
    
    def _save_report(self):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’JSONå½¢å¼ã§ä¿å­˜"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"test_report_{timestamp}.json"
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'total_duration': time.time() - self.total_start_time,
            'results': self.results,
            'summary': {
                'total_tests': sum(r['tests_run'] for r in self.results.values()),
                'total_success': sum(r['success_count'] for r in self.results.values()),
                'total_failures': sum(r['failures'] for r in self.results.values()),
                'total_errors': sum(r['errors'] for r in self.results.values()),
                'total_skipped': sum(r['skipped'] for r in self.results.values())
            }
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
        except Exception as e:
            print(f"\nâŒ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã«å¤±æ•—: {e}")
    
    def run_specific_categories(self, categories=None):
        """ç‰¹å®šã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ"""
        if categories is None:
            categories = ['basic', 'integration', 'performance']
        
        category_mapping = {
            'basic': ['test_basic'],
            'attendance': ['test_attendance'],
            'integration': ['test_database_integration'],
            'error': ['test_error_handling'],
            'performance': ['test_performance']
        }
        
        modules_to_run = []
        for category in categories:
            if category in category_mapping:
                modules_to_run.extend(category_mapping[category])
        
        # é‡è¤‡é™¤å»
        modules_to_run = list(set(modules_to_run))
        
        print(f"ğŸ¯ ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {categories}")
        print(f"å®Ÿè¡Œäºˆå®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {modules_to_run}")
        
        self.test_modules = modules_to_run
        return self.run_all_tests()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼')
    parser.add_argument('--verbosity', '-v', type=int, default=2, 
                       help='å‡ºåŠ›ã®è©³ç´°ãƒ¬ãƒ™ãƒ« (0-2)')
    parser.add_argument('--no-report', action='store_true',
                       help='ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ãªã„')
    parser.add_argument('--categories', nargs='+', 
                       choices=['basic', 'attendance', 'integration', 'error', 'performance'],
                       help='å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’æŒ‡å®š')
    parser.add_argument('--modules', nargs='+',
                       help='å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç›´æ¥æŒ‡å®š')
    
    args = parser.parse_args()
    
    runner = TestSuiteRunner()
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç›´æ¥æŒ‡å®šã®å ´åˆ
    if args.modules:
        runner.test_modules = args.modules
        success = runner.run_all_tests(args.verbosity, not args.no_report)
    # ã‚«ãƒ†ã‚´ãƒªæŒ‡å®šã®å ´åˆ
    elif args.categories:
        success = runner.run_specific_categories(args.categories)
    # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    else:
        success = runner.run_all_tests(args.verbosity, not args.no_report)
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®š
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main() 